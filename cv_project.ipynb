{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import copy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthDataset(Dataset):\n",
    "    def __init__(self, rgb, depth):\n",
    "        self.input = rgb\n",
    "        self.output = depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_path = self.input[index]\n",
    "        output_path = self.output[index]\n",
    "\n",
    "        with Image.open(input_path) as input_image, Image.open(output_path) as output_image:\n",
    "            rgb = torch.tensor(np.array(input_image) / 255, dtype=torch.float).reshape(3,480,640)\n",
    "            depth = torch.tensor(np.array(output_image), dtype=torch.float)\n",
    "\n",
    "        return rgb, depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = glob.glob('./sync/**/rgb*', recursive = True)\n",
    "depth = glob.glob('./sync/**/sync*', recursive = True)\n",
    "rgb.sort()\n",
    "depth.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(rgb, depth, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable cudnn benchmark mode\n",
    "cudnn.benchmark = True\n",
    "\n",
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Initialize the weights of conv layers\n",
    "        init.xavier_uniform_(self.conv1.weight.data)\n",
    "        init.xavier_uniform_(self.conv2.weight.data)\n",
    "        init.xavier_uniform_(self.conv3.weight.data)\n",
    "        init.xavier_uniform_(self.conv4.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.upsample(out)\n",
    "        out = self.conv4(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0005\n",
    "num_epochs = 5\n",
    "batch_size = 8\n",
    "wd = 0.001\n",
    "\n",
    "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 0}\n",
    "train_loader = DataLoader(DepthDataset(X_train, y_train), **params)\n",
    "val_loader = DataLoader(DepthDataset(X_val, y_val), **params)\n",
    "test_loader = DataLoader(DepthDataset(X_test, y_test), **params)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ConvNeuralNet().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=wd)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.01, patience=3)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 2897115.8999\n",
      "New best validation loss at epoch 1\n",
      "Epoch [1/10], Validation Loss: 2792465.7228\n",
      "Accuracy on the validation set: 32.533%\n",
      "Epoch [2/10], Training Loss: 2734593.1695\n",
      "New best validation loss at epoch 2\n",
      "Epoch [2/10], Validation Loss: 2754384.7781\n",
      "Accuracy on the validation set: 32.533%\n",
      "Epoch [3/10], Training Loss: 2678832.0774\n",
      "New best validation loss at epoch 3\n",
      "Epoch [3/10], Validation Loss: 2718544.9523\n",
      "Accuracy on the validation set: 32.533%\n",
      "Epoch [4/10], Training Loss: 2643485.5892\n",
      "New best validation loss at epoch 4\n",
      "Epoch [4/10], Validation Loss: 2671863.4641\n",
      "Accuracy on the validation set: 32.533%\n",
      "Epoch [5/10], Training Loss: 2622481.3601\n",
      "New best validation loss at epoch 5\n",
      "Epoch [5/10], Validation Loss: 2634731.2530\n",
      "Accuracy on the validation set: 32.533%\n",
      "Epoch [6/10], Training Loss: 2603454.5298\n",
      "New best validation loss at epoch 6\n",
      "Epoch [6/10], Validation Loss: 2621532.0092\n",
      "Accuracy on the validation set: 32.533%\n",
      "Epoch [7/10], Training Loss: 2592795.2286\n",
      "Epoch [7/10], Validation Loss: 2646670.7838\n",
      "Accuracy on the validation set: 32.533%\n",
      "Epoch [8/10], Training Loss: 2584749.0275\n",
      "New best validation loss at epoch 8\n",
      "Epoch [8/10], Validation Loss: 2601600.3777\n",
      "Accuracy on the validation set: 32.533%\n",
      "Epoch [9/10], Training Loss: 2579665.0338\n",
      "Epoch [9/10], Validation Loss: 2602133.7440\n",
      "Accuracy on the validation set: 32.533%\n",
      "Epoch [10/10], Training Loss: 2574742.5206\n",
      "Epoch [10/10], Validation Loss: 2626383.2826\n",
      "Accuracy on the validation set: 32.533%\n"
     ]
    }
   ],
   "source": [
    "# We use the pre-defined number of epochs to determine how many iterations to train the network on\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Initialize early stopping variables\n",
    "best_val_loss = float('inf')\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "threshold = 1000\n",
    "counter = 0  # Counter to track the number of epochs without improvement\n",
    "best_weights = None\n",
    "history = []\n",
    "\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Training\n",
    "    for i, (local_batch, local_labels) in enumerate(train_loader, 1):\n",
    "        # Move tensors to the configured device\n",
    "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        with autocast():\n",
    "            outputs = model(local_batch)\n",
    "            loss = criterion(outputs, local_labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Free up GPU Memory cache\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    print('Epoch [{}/{}], Training Loss: {:.4f}'.format(epoch, num_epochs, train_loss))\n",
    "\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        loss_sum = 0\n",
    "        correct = 0\n",
    "        \n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss_sum += criterion(outputs, labels).item()\n",
    "        \n",
    "        val_loss = loss_sum / len(val_loader)\n",
    "        print('Epoch [{}/{}], Validation Loss: {:.4f}'.format(epoch, num_epochs, val_loss))\n",
    "        history.append((\"Epoch \" + str(epoch), val_loss))\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss - threshold:\n",
    "            print(\"New best validation loss at epoch\", epoch)\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0  # Reset the counter when there is improvement\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping at epoch\", epoch)\n",
    "                break\n",
    "        scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Epoch 1', 2792465.722802198), ('Epoch 2', 2754384.7780906595), ('Epoch 3', 2718544.9522664836), ('Epoch 4', 2671863.4641483515), ('Epoch 5', 2634731.253021978), ('Epoch 6', 2621532.0092032966), ('Epoch 7', 2646670.7837912086), ('Epoch 8', 2601600.3776785713), ('Epoch 9', 2602133.744024725), ('Epoch 10', 2626383.282554945)]\n"
     ]
    }
   ],
   "source": [
    "torch.save(best_weights, './model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on the test set: 2547449.192\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(best_weights)\n",
    "\n",
    "with torch.no_grad():\n",
    "    mse = 0.0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        mse += criterion(outputs, labels).item() * images.size(0)\n",
    "    \n",
    "    mse /= len(X_test)\n",
    "    print('Mean Squared Error on the test set: {:.3f}'.format(mse))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
